# -*- coding: utf-8 -*-
"""preprocessing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ts3YlkPKcDsX8yW6KiEd0ZtfqAOlixXE

# Pascal VOC 2012 데이터셋 구조
[참고 블로그](https://bo-10000.tistory.com/38)
* Annotations : 각 데이터의 Object class, Bounding box와 기타 부가 정보들이 들어 있는 xml 파일
* ImageSets : 각 Task에 해당하는 데이터의 파일명이 나열된 txt 파일
* JPEGImages : JPEG 원본 이미지
* SegmentationClass : Semantic Segmentation을 위한 라벨 PNG 파일
* SegmentationObject : Instance Segmentation을 위한 라벨 PNG 파일


---


> 각 물체는 픽셀 값으로 구분됨.
> 각 픽셀 값이 나타내는 class는 SegmentationClass 라벨과 SegmentationObject 라벨이 서로 다름.



---


> SegmentationObject 라벨 이미지는 Class마다 해당되는 픽셀 값이 정해져 있지 않고, 각 Instance마다 번호를 붙인다. 각 Instance의 Class 정보는 Annotations 폴더의 xml 파일에 정리되어 있다.
"""

# 구글 드라이브 마운트
from google.colab import drive
drive.mount('/content/drive')

cd /content/drive/MyDrive/dataset

pwd

# VOC class names
classes = [
    "aeroplane",
    "bicycle",
    "bird",
    "boat",
    "bottle",
    "bus",
    "car",
    "cat",
    "chair",
    "cow",
    "diningtable",
    "dog",
    "horse",
    "motorbike",
    "person",
    "pottedplant",
    "sheep",
    "sofa",
    "train",
    "tvmonitor"
]

# Commented out IPython magic to ensure Python compatibility.
# https://data-panic.tistory.com/13

from PIL import Image
# %matplotlib inline
import matplotlib
import matplotlib.pyplot as plt
import torch
from torch.utils.data import Dataset, DataLoader
import numpy as np
import torchvision
from torchvision import transforms

# Pascal VOC는 각 이미지의 크기가 다르므로 resize
trans = transforms.Compose([transforms.Resize((100,100)),
                            transforms.ToTensor(),
                            transforms.Normalize((0.5,0.5,0.5),(0.5, 0.5, 0.5))
                            ])
trainset = torchvision.datasets.ImageFolder(root = "./pascal", 
                                            transform=trans)

len(trainset)

trainset.__geitem__(18)

